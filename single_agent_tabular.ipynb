{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Video\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bitmap_single_black(show=True):\n",
    "    # Start with an all-white 8x8 bitmap\n",
    "    bitmap = np.zeros((8, 8), dtype=int)\n",
    "\n",
    "    # Randomly select a position for the single black pixel\n",
    "    black_pixel_position = np.random.randint(0, 8, 2)\n",
    "    bitmap[black_pixel_position[0], black_pixel_position[1]] = 1\n",
    "\n",
    "    # Displaying the bitmap\n",
    "    if show:\n",
    "        plt.imshow(bitmap, cmap='grey')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return bitmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFD0lEQVR4nO3bMYrEQBAEQfWh/3+5z0tbLIhZlgh7jPKSNmZ2dy8AuK7r7/QAAL6HKAAQUQAgogBARAGAiAIAEQUAIgoA5H76cGbe3AHAy578VXYpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGA3KcH8Ht29/SEj8zM6QlwnEsBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkPv0AH7PzJyeAHzIpQBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDkfvpwd9/cAcAXcCkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJB/YYkQDnzOslUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_bitmap_single_black()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitmap = generate_bitmap_single_black(show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(bitmap)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSAAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01):\n",
    "        # Initialize the agent's Q-table to zeros\n",
    "        self.q_table = np.zeros((8, 8, 9))  # 8x8 grid and 9 possible actions\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.epsilon_decay = epsilon_decay  # Decay rate of exploration\n",
    "        self.epsilon_min = epsilon_min  # Minimum exploration rate\n",
    "        \n",
    "        # Define the action space\n",
    "        self.actions = ['up', 'down', 'left', 'right', 'up_left', 'up_right', 'down_left', 'down_right', 'stay']\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore: choose a random action\n",
    "            return np.random.choice(self.actions)\n",
    "        else:\n",
    "            # Exploit: choose the best action from Q-table\n",
    "            x, y = state\n",
    "            return self.actions[np.argmax(self.q_table[x, y])]\n",
    "\n",
    "    def get_next_state(self, current_state, action):\n",
    "        # This function returns the next state based on the current state and action\n",
    "        x, y = current_state\n",
    "        if action == 'up':\n",
    "            return (max(x-1, 0), y)\n",
    "        elif action == 'down':\n",
    "            return (min(x+1, 7), y)\n",
    "        elif action == 'left':\n",
    "            return (x, max(y-1, 0))\n",
    "        elif action == 'right':\n",
    "            return (x, min(y+1, 7))\n",
    "        elif action == 'up_left':\n",
    "            return (max(x-1, 0), max(y-1, 0))\n",
    "        elif action == 'up_right':\n",
    "            return (max(x-1, 0), min(y+1, 7))\n",
    "        elif action == 'down_left':\n",
    "            return (min(x+1, 7), max(y-1, 0))\n",
    "        elif action == 'down_right':\n",
    "            return (min(x+1, 7), min(y+1, 7))\n",
    "        else:\n",
    "            return current_state\n",
    "\n",
    "    def action_index(self, action):\n",
    "        return self.actions.index(action)\n",
    "\n",
    "    def update(self, current_state, action, reward, next_state, next_action):\n",
    "        # Convert actions to their index in the Q-table\n",
    "        action_index = self.action_index(action)\n",
    "        next_action_index = self.action_index(next_action)\n",
    "\n",
    "        # Perform the SARSA update to the Q-table\n",
    "        current_q = self.q_table[current_state + (action_index,)]\n",
    "        next_q = self.q_table[next_state + (next_action_index,)]\n",
    "        target_q = reward + self.gamma * next_q\n",
    "        self.q_table[current_state + (action_index,)] += self.alpha * (target_q - current_q)\n",
    "\n",
    "        # Decay epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll re-use the train_agent function with minor modifications for SARSA\n",
    "def train_agent(agent, goal_position, episodes=1000, verbose=False):\n",
    "    for episode in range(episodes):\n",
    "        # Start from a random position\n",
    "        current_position = (np.random.randint(8), np.random.randint(8))\n",
    "        current_action = agent.choose_action(current_position)\n",
    "\n",
    "        while current_position != goal_position:\n",
    "            next_position = agent.get_next_state(current_position, current_action)\n",
    "            next_action = agent.choose_action(next_position)\n",
    "            reward = -1  # Reward of -1 for each transition\n",
    "            agent.update(current_position, current_action, reward, next_position, next_action)\n",
    "            current_position, current_action = next_position, next_action\n",
    "\n",
    "        # Optionally: Print out the Q-table every 100 episodes\n",
    "        if verbose and episode % 100 == 0:\n",
    "            print(f\"Episode {episode}: Epsilon {agent.epsilon}\")\n",
    "            print(agent.q_table[:, :, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFEElEQVR4nO3bMWrEQBBFQbXR/a/czl4sFsSscVU8wc8eHczs7l4AcF3Xz+kBAHwPUQAgogBARAGAiAIAEQUAIgoARBQAyP304cy8uQOAlz35q+xSACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFAHKfHvC23T094SMzc3oC8A+5FACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYDcpwe8bWZOTwD4M1wKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBA7qcPd/fNHQB8AZcCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgD5BR2AEA7IeMpnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "b = generate_bitmap_single_black(show=True)\n",
    "goal = np.where(b)\n",
    "goal_position = (goal[0][0], goal[1][0])\n",
    "print(goal_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFD0lEQVR4nO3bMWrAQBAEQa3R/7+8zjoWBnHCVMUXTNZscLO7ewHAdV0/pwcA8B2iAEBEAYCIAgARBQAiCgBEFACIKACQ++nDmXlzBwAve/JX2aUAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADIfXoAfMXunp7wJzNzegL/iEsBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyH16AHzFzJyeAMe5FACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEDupw93980dAHyASwGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgPwCf7cQDim9N+4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-1.07553787, -1.03106269, -0.99963001, -1.0478908 ,\n",
       "         -1.01162911, -1.1243209 , -1.02060888, -1.14657756,\n",
       "         -1.17736512],\n",
       "        [-1.67774298, -1.70988025, -1.68087367, -1.67560404,\n",
       "         -1.71064749, -1.79015359, -1.69462087, -1.75536591,\n",
       "         -1.76276043],\n",
       "        [-2.01561679, -2.01532966, -1.94984404, -2.06592227,\n",
       "         -2.01019763, -1.95456885, -1.9842471 , -1.98577883,\n",
       "         -1.99090245]],\n",
       "\n",
       "       [[-1.03561038, -1.12684209, -1.01775821, -1.01613045,\n",
       "         -0.99996356, -1.03331486, -1.12798674, -1.06348497,\n",
       "         -1.10250813],\n",
       "        [-1.75414318, -1.75354267, -1.7144434 , -1.80601927,\n",
       "         -1.71120462, -1.81248698, -1.75877485, -1.78372465,\n",
       "         -1.76347118],\n",
       "        [-1.9875826 , -1.97356898, -2.00110587, -1.9970358 ,\n",
       "         -2.02437478, -2.00692433, -1.98510828, -1.99962007,\n",
       "         -2.07279903]],\n",
       "\n",
       "       [[-1.65307376, -1.75060975, -1.6808718 , -1.64623772,\n",
       "         -1.63466647, -1.70703513, -1.70103135, -1.67159299,\n",
       "         -1.75986748],\n",
       "        [-1.85802396, -1.90846475, -1.83035256, -1.80618588,\n",
       "         -1.78858033, -1.84777605, -1.79412051, -1.83179633,\n",
       "         -1.92095959],\n",
       "        [-2.05986188, -2.05682669, -1.99849526, -2.05846572,\n",
       "         -2.01364595, -2.00207676, -2.02217424, -2.06192986,\n",
       "         -2.07119134]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SARSA agent\n",
    "sarsa_agent = SARSAAgent()\n",
    "bitmap = generate_bitmap_single_black(show=True)\n",
    "goal = np.where(bitmap)\n",
    "goal_position = (goal[0][0], goal[1][0])\n",
    "print(goal_position)\n",
    "\n",
    "# Train the SARSA agent with verbose output turned off for brevity\n",
    "train_agent(sarsa_agent, goal_position, verbose=False)\n",
    "\n",
    "# Return a slice of the Q-table for brevity in displaying the result\n",
    "sarsa_agent.q_table[5:8, 5:8, :]  # Displaying a slice of the Q-table for the bottom-right corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(agent, grid, start_position, goal_position, filename='agent_movement.mp4'):\n",
    "    # Set up the video writer with a higher FPS to slow down the movement\n",
    "    writer = imageio.get_writer(filename, fps=3)\n",
    "\n",
    "    # Increase the size of the grid for better visibility\n",
    "    scale_factor = 50  # Increase this if you want even larger frames\n",
    "    large_grid = np.kron(grid, np.ones((scale_factor, scale_factor)))\n",
    "\n",
    "    # Assume goal_position and all grid positions are initially 0 (black)\n",
    "    # Set the goal position to 1 (white)\n",
    "    grid[goal_position] = 1\n",
    "\n",
    "    for step in range(100):  # Assume a maximum of 100 steps\n",
    "        # Update the grid with the current agent position (set to 1 for white)\n",
    "        grid[start_position] = 1\n",
    "        large_grid = np.kron(grid, np.ones((scale_factor, scale_factor)))  # Scale up\n",
    "        frame = (large_grid * 255).astype(np.uint8)  # Convert to an image\n",
    "        frame = np.stack((frame,) * 3, axis=-1)  # Convert to RGB\n",
    "\n",
    "        # Repeat each frame three times\n",
    "        for _ in range(3):\n",
    "            writer.append_data(frame)\n",
    "\n",
    "        # Set the agent's previous position back to 0 (black)\n",
    "        grid[start_position] = 0\n",
    "\n",
    "        # Move the agent\n",
    "        action = agent.choose_action(start_position)\n",
    "        next_position = agent.get_next_state(start_position, action)\n",
    "\n",
    "        # If the agent reaches the goal, update the grid and append the final frames\n",
    "        if next_position == goal_position:\n",
    "            grid[next_position] = 1  # Set the agent position to white\n",
    "            large_grid = np.kron(grid, np.ones((scale_factor, scale_factor)))\n",
    "            final_frame = (large_grid * 255).astype(np.uint8)\n",
    "            final_frame = np.stack((final_frame,) * 3, axis=-1)\n",
    "            for _ in range(3):\n",
    "                writer.append_data(final_frame)\n",
    "            break  # Break after showing the final move\n",
    "\n",
    "        # Update the start position for the next step\n",
    "        start_position = next_position\n",
    "\n",
    "    writer.close()  # Close the writer to finalize the video\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"untrained.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untrained agent\n",
    "Video(make_video(SARSAAgent(), bitmap, (np.random.randint(8), np.random.randint(8)), goal_position, filename=\"untrained.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"trained.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trained agent\n",
    "Video(make_video(sarsa_agent, bitmap, (np.random.randint(8), np.random.randint(8)), goal_position, filename=\"trained.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-organising-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
