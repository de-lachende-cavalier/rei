{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with a single agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Video\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bitmap_single_black(show=True, show_goal=True):\n",
    "    # Start with an all-white 8x8 bitmap\n",
    "    bitmap = np.zeros((8, 8), dtype=int)\n",
    "\n",
    "    # Randomly select a position for the single black pixel\n",
    "    goal_position = np.random.randint(0, 8, 2)\n",
    "    if show_goal:\n",
    "        bitmap[goal_position[0], goal_position[1]] = 1\n",
    "\n",
    "    # Displaying the bitmap\n",
    "    if show:\n",
    "        plt.imshow(bitmap)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return bitmap, (goal_position[0], goal_position[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFI0lEQVR4nO3XsWkDURRFwZXYKlSFmhBbgatUBcJNuAqXoe/sRAKbBfEXPBO/4GaHdxpjjAUAlmU5zx4AwHGIAgARBQAiCgBEFACIKAAQUQAgogBA1r8e3s4f79wBwJt9Pu+/3vgUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAZJ09gNce31+zJ+y2Xa6zJwA7+RQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGArLMH8Np2uc6eAPxDPgUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDkNMYYs0cAcAw+BQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUA8gNSRRGYsBIbXAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " (4, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_bitmap_single_black()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSAAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01):\n",
    "        # Initialize the agent's Q-table to zeros\n",
    "        self.q_table = np.zeros((8, 8, 9))  # 8x8 grid and 9 possible actions\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.epsilon_decay = epsilon_decay  # Decay rate of exploration\n",
    "        self.epsilon_min = epsilon_min  # Minimum exploration rate\n",
    "        \n",
    "        # Define the action space\n",
    "        self.actions = ['up', 'down', 'left', 'right', 'up_left', 'up_right', 'down_left', 'down_right', 'stay']\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore: choose a random action\n",
    "            return np.random.choice(self.actions)\n",
    "        else:\n",
    "            # Exploit: choose the best action from Q-table\n",
    "            x, y = state\n",
    "            return self.actions[np.argmax(self.q_table[x, y])]\n",
    "\n",
    "    def get_next_state(self, current_state, action):\n",
    "        # This function returns the next state based on the current state and action\n",
    "        x, y = current_state\n",
    "        if action == 'up':\n",
    "            return (max(x-1, 0), y)\n",
    "        elif action == 'down':\n",
    "            return (min(x+1, 7), y)\n",
    "        elif action == 'left':\n",
    "            return (x, max(y-1, 0))\n",
    "        elif action == 'right':\n",
    "            return (x, min(y+1, 7))\n",
    "        elif action == 'up_left':\n",
    "            return (max(x-1, 0), max(y-1, 0))\n",
    "        elif action == 'up_right':\n",
    "            return (max(x-1, 0), min(y+1, 7))\n",
    "        elif action == 'down_left':\n",
    "            return (min(x+1, 7), max(y-1, 0))\n",
    "        elif action == 'down_right':\n",
    "            return (min(x+1, 7), min(y+1, 7))\n",
    "        else:\n",
    "            return current_state\n",
    "\n",
    "    def action_index(self, action):\n",
    "        return self.actions.index(action)\n",
    "\n",
    "    def update(self, current_state, action, reward, next_state, next_action):\n",
    "        # Convert actions to their index in the Q-table\n",
    "        action_index = self.action_index(action)\n",
    "        next_action_index = self.action_index(next_action)\n",
    "\n",
    "        # Perform the SARSA update to the Q-table\n",
    "        current_q = self.q_table[current_state + (action_index,)]\n",
    "        next_q = self.q_table[next_state + (next_action_index,)]\n",
    "        target_q = reward + self.gamma * next_q\n",
    "        self.q_table[current_state + (action_index,)] += self.alpha * (target_q - current_q)\n",
    "\n",
    "        # Decay epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll re-use the train_agent function with minor modifications for SARSA\n",
    "def train_agent(agent, goal_position, episodes=1000, verbose=False):\n",
    "    for episode in range(episodes):\n",
    "        # Start from a random position\n",
    "        current_position = (np.random.randint(8), np.random.randint(8))\n",
    "        current_action = agent.choose_action(current_position)\n",
    "\n",
    "        while current_position != goal_position:\n",
    "            next_position = agent.get_next_state(current_position, current_action)\n",
    "            next_action = agent.choose_action(next_position)\n",
    "            reward = -1  # Reward of -1 for each transition\n",
    "            agent.update(current_position, current_action, reward, next_position, next_action)\n",
    "            current_position, current_action = next_position, next_action\n",
    "\n",
    "        # Optionally: Print out the Q-table every 100 episodes\n",
    "        if verbose and episode % 100 == 0:\n",
    "            print(f\"Episode {episode}: Epsilon {agent.epsilon}\")\n",
    "            print(agent.q_table[:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFHklEQVR4nO3XsakCURRF0VGmCquwCfkVWKUViE1YhWX4frZTRRiewlrxDU62ubsxxlgAYFmW/ewBAHwPUQAgogBARAGAiAIAEQUAIgoARBQAyPru4Wl/3nIHABu7PS8vb3wKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkHX2AIBfc33cZ0/YjE8BgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkHX2AIBf83c4zp7wkdvz9Y1PAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkN0YY8weAcB38CkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJB/1VASwDMw5ucAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-2.6587252 , -2.71563265, -2.69938194, -2.67546449,\n",
       "         -2.72313526, -2.65392454, -2.66246816, -2.67507907,\n",
       "         -2.66133779],\n",
       "        [-2.5681955 , -2.63149777, -2.62231767, -2.58146179,\n",
       "         -2.56180246, -2.5642963 , -2.65122652, -2.56287734,\n",
       "         -2.59584094],\n",
       "        [-2.538004  , -2.54693795, -2.5287255 , -2.65041244,\n",
       "         -2.53115847, -2.53036506, -2.56854272, -2.583011  ,\n",
       "         -2.65977719]],\n",
       "\n",
       "       [[-3.10677789, -3.08833704, -3.15060257, -3.13500892,\n",
       "         -3.10627452, -3.09818605, -3.09012858, -3.13325651,\n",
       "         -3.14528459],\n",
       "        [-2.99533203, -3.04023396, -3.03867608, -3.0004213 ,\n",
       "         -2.98813121, -3.01176209, -2.99690806, -3.002844  ,\n",
       "         -3.00867172],\n",
       "        [-2.93400455, -2.92237587, -2.98337371, -2.92852383,\n",
       "         -2.92295424, -2.91321993, -2.93136767, -2.95520299,\n",
       "         -2.94183095]],\n",
       "\n",
       "       [[-3.30254782, -3.3337981 , -3.27719446, -3.28661941,\n",
       "         -3.29156678, -3.28204067, -3.29915554, -3.32010868,\n",
       "         -3.26414643],\n",
       "        [-3.20298849, -3.1961037 , -3.20730961, -3.1989231 ,\n",
       "         -3.22094212, -3.22198222, -3.2498562 , -3.22779791,\n",
       "         -3.20445231],\n",
       "        [-3.10200292, -3.11852548, -3.16503224, -3.13110012,\n",
       "         -3.11254376, -3.12075545, -3.12883756, -3.1985257 ,\n",
       "         -3.15672229]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SARSA agent\n",
    "sarsa_agent = SARSAAgent()\n",
    "bitmap, goal_position = generate_bitmap_single_black(show=True, show_goal=True)\n",
    "print(goal_position)\n",
    "\n",
    "# Train the SARSA agent with verbose output turned off for brevity\n",
    "train_agent(sarsa_agent, goal_position, verbose=False)\n",
    "\n",
    "# Return a slice of the Q-table for brevity in displaying the result\n",
    "sarsa_agent.q_table[5:8, 5:8, :]  # Displaying a slice of the Q-table for the bottom-right corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(agent, grid, start_position, goal_position, filename='agent_movement.mp4'):\n",
    "    # Set up the video writer with a higher FPS to slow down the movement\n",
    "    writer = imageio.get_writer(filename, fps=3)\n",
    "\n",
    "    # Increase the size of the grid for better visibility\n",
    "    scale_factor = 50  # Increase this if you want even larger frames\n",
    "    large_grid = np.kron(grid, np.ones((scale_factor, scale_factor)))\n",
    "\n",
    "    # Assume goal_position and all grid positions are initially 0 (black)\n",
    "    # Set the goal position to 1 (white)\n",
    "    grid[goal_position] = 1\n",
    "\n",
    "    for step in range(100):  # Assume a maximum of 100 steps\n",
    "        # Update the grid with the current agent position (set to 1 for white)\n",
    "        grid[start_position] = 1\n",
    "        large_grid = np.kron(grid, np.ones((scale_factor, scale_factor)))  # Scale up\n",
    "        frame = (large_grid * 255).astype(np.uint8)  # Convert to an image\n",
    "        frame = np.stack((frame,) * 3, axis=-1)  # Convert to RGB\n",
    "\n",
    "        # Repeat each frame three times\n",
    "        for _ in range(3):\n",
    "            writer.append_data(frame)\n",
    "\n",
    "        # Set the agent's previous position back to 0 (black)\n",
    "        grid[start_position] = 0\n",
    "\n",
    "        # Move the agent\n",
    "        action = agent.choose_action(start_position)\n",
    "        next_position = agent.get_next_state(start_position, action)\n",
    "\n",
    "        # If the agent reaches the goal, update the grid and append the final frames\n",
    "        if next_position == goal_position:\n",
    "            grid[next_position] = 1  # Set the agent position to white\n",
    "            large_grid = np.kron(grid, np.ones((scale_factor, scale_factor)))\n",
    "            final_frame = (large_grid * 255).astype(np.uint8)\n",
    "            final_frame = np.stack((final_frame,) * 3, axis=-1)\n",
    "            for _ in range(3):\n",
    "                writer.append_data(final_frame)\n",
    "            break  # Break after showing the final move\n",
    "\n",
    "        # Update the start position for the next step\n",
    "        start_position = next_position\n",
    "\n",
    "    writer.close()  # Close the writer to finalize the video\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"untrained.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untrained agent\n",
    "Video(make_video(SARSAAgent(), bitmap, (np.random.randint(8), np.random.randint(8)), goal_position, filename=\"untrained.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"trained.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trained agent\n",
    "Video(make_video(sarsa_agent, bitmap, (np.random.randint(8), np.random.randint(8)), goal_position, filename=\"trained.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-organising-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
