{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with a single agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Video\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bitmap_single_black(show=True, show_goal=True):\n",
    "    # Start with an all-white 8x8 bitmap\n",
    "    bitmap = np.zeros((8, 8), dtype=int)\n",
    "\n",
    "    # Randomly select a position for the single black pixel\n",
    "    goal_position = np.random.randint(0, 8, 2)\n",
    "    if show_goal:\n",
    "        bitmap[goal_position[0], goal_position[1]] = 1\n",
    "\n",
    "    # Displaying the bitmap\n",
    "    if show:\n",
    "        plt.imshow(bitmap)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return bitmap, (goal_position[0], goal_position[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFHklEQVR4nO3XsY3CUBRFQYNcBVXQBKKCrZIK0DZBFZTBJzvpOvmyV5qJX3Czo3caY4wFAJZlOe89AIDjEAUAIgoARBQAiCgAEFEAIKIAQEQBgKxbD2/nn5k7AJjs9/P488anAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIOvWw+f7NXHGPPfLde8JAP+GTwGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADIuvXwfrlOnAHAEfgUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkNMYY+w9AoBj8CkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJAvdUQRmNI0vnQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " (4, 0))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_bitmap_single_black()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSAAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01):\n",
    "        # Initialize the agent's Q-table to zeros\n",
    "        self.q_table = np.zeros((8, 8, 9))  # 8x8 grid and 9 possible actions\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "        self.epsilon_decay = epsilon_decay  # Decay rate of exploration\n",
    "        self.epsilon_min = epsilon_min  # Minimum exploration rate\n",
    "        \n",
    "        # Define the action space\n",
    "        self.actions = ['up', 'down', 'left', 'right', 'up_left', 'up_right', 'down_left', 'down_right', 'stay']\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore: choose a random action\n",
    "            return np.random.choice(self.actions)\n",
    "        else:\n",
    "            # Exploit: choose the best action from Q-table\n",
    "            x, y = state\n",
    "            return self.actions[np.argmax(self.q_table[x, y])]\n",
    "\n",
    "    def get_next_state(self, current_state, action):\n",
    "        # This function returns the next state based on the current state and action\n",
    "        x, y = current_state\n",
    "        if action == 'up':\n",
    "            return (max(x-1, 0), y)\n",
    "        elif action == 'down':\n",
    "            return (min(x+1, 7), y)\n",
    "        elif action == 'left':\n",
    "            return (x, max(y-1, 0))\n",
    "        elif action == 'right':\n",
    "            return (x, min(y+1, 7))\n",
    "        elif action == 'up_left':\n",
    "            return (max(x-1, 0), max(y-1, 0))\n",
    "        elif action == 'up_right':\n",
    "            return (max(x-1, 0), min(y+1, 7))\n",
    "        elif action == 'down_left':\n",
    "            return (min(x+1, 7), max(y-1, 0))\n",
    "        elif action == 'down_right':\n",
    "            return (min(x+1, 7), min(y+1, 7))\n",
    "        else:\n",
    "            return current_state\n",
    "\n",
    "    def action_index(self, action):\n",
    "        return self.actions.index(action)\n",
    "\n",
    "    def update(self, current_state, action, reward, next_state, next_action):\n",
    "        # Convert actions to their index in the Q-table\n",
    "        action_index = self.action_index(action)\n",
    "        next_action_index = self.action_index(next_action)\n",
    "\n",
    "        # Perform the SARSA update to the Q-table\n",
    "        current_q = self.q_table[current_state + (action_index,)]\n",
    "        next_q = self.q_table[next_state + (next_action_index,)]\n",
    "        target_q = reward + self.gamma * next_q\n",
    "        self.q_table[current_state + (action_index,)] += self.alpha * (target_q - current_q)\n",
    "\n",
    "        # Decay epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(agent, goal_position, episodes=1000, verbose=False):\n",
    "    for episode in range(episodes):\n",
    "        # Start from a random position\n",
    "        current_position = (np.random.randint(8), np.random.randint(8))\n",
    "        current_action = agent.choose_action(current_position)\n",
    "\n",
    "        while current_position != goal_position:\n",
    "            next_position = agent.get_next_state(current_position, current_action)\n",
    "            next_action = agent.choose_action(next_position)\n",
    "            reward = -1  # Reward of -1 for each transition\n",
    "            agent.update(current_position, current_action, reward, next_position, next_action)\n",
    "            current_position, current_action = next_position, next_action\n",
    "\n",
    "        # Optionally: Print out the Q-table every 100 episodes\n",
    "        if verbose and episode % 100 == 0:\n",
    "            print(f\"Episode {episode}: Epsilon {agent.epsilon}\")\n",
    "            print(agent.q_table[:, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFI0lEQVR4nO3XwWkCURSG0RmZKqYKmxArsMpUENKEVViGL7tvFTBE5Ek4Z30X/+7jrmOMsQDAsiyH2QMAeB+iAEBEAYCIAgARBQAiCgBEFACIKACQ7beHp8PllTsAeLGv+8fDG58CABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAbLMHAM/5vF1nT/iT836cPYEf+BQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAbLMHAM8578fZE/hHfAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFADIOsYYs0cA8B58CgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoA5BuVJRGYLIaoUgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.99949247, -1.03855137, -1.08546525, -1.03870857,\n",
       "         -1.0749523 , -1.03860299, -1.14229676, -1.05578662,\n",
       "         -1.09886013],\n",
       "        [-1.02757579, -1.02521796, -1.0451715 , -1.01985093,\n",
       "         -0.99996356, -1.10939518, -1.19742174, -1.08964479,\n",
       "         -1.0981555 ],\n",
       "        [-1.65472819, -1.65268383, -1.59117859, -1.59081006,\n",
       "         -1.61666844, -1.60243074, -1.61098634, -1.67406922,\n",
       "         -1.60452408]],\n",
       "\n",
       "       [[-1.70300794, -1.75755306, -1.7482582 , -1.73326999,\n",
       "         -1.69497395, -1.69119721, -1.77935846, -1.76528582,\n",
       "         -1.76349346],\n",
       "        [-1.72926796, -1.82873974, -1.73457175, -1.78467817,\n",
       "         -1.7296731 , -1.75748517, -1.79890459, -1.75251776,\n",
       "         -1.76159633],\n",
       "        [-1.82486871, -1.8676946 , -1.85229193, -1.90976679,\n",
       "         -1.79894223, -1.79177717, -1.89195659, -1.78788187,\n",
       "         -1.9262618 ]],\n",
       "\n",
       "       [[-2.04767002, -2.06161272, -2.09725569, -2.02317555,\n",
       "         -2.0623301 , -2.01767504, -2.04736651, -2.04352523,\n",
       "         -2.07210148],\n",
       "        [-1.96791864, -2.06094907, -2.02197031, -1.96770857,\n",
       "         -2.02020834, -1.97227983, -2.04123928, -1.99821473,\n",
       "         -2.07020982],\n",
       "        [-2.02517677, -2.05749323, -2.04601962, -2.13031122,\n",
       "         -2.04100387, -2.04651937, -2.01395991, -2.06303302,\n",
       "         -2.07017126]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SARSA agent\n",
    "sarsa_agent = SARSAAgent()\n",
    "bitmap, goal_position = generate_bitmap_single_black(show=True, show_goal=True)\n",
    "print(goal_position)\n",
    "\n",
    "# Train the SARSA agent with verbose output turned off for brevity\n",
    "train_agent(sarsa_agent, goal_position, verbose=False)\n",
    "\n",
    "# Return a slice of the Q-table for brevity in displaying the result\n",
    "sarsa_agent.q_table[5:8, 5:8, :]  # Displaying a slice of the Q-table for the bottom-right corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_video(agent, grid, start_position, goal_position, filename='agent_movement.mp4'):\n",
    "    # Set up the video writer with a higher FPS to slow down the movement\n",
    "    writer = imageio.get_writer(\"videos/\" + filename, fps=3)\n",
    "\n",
    "    # Increase the size of the grid for better visibility\n",
    "    scale_factor = 50  # Increase this if you want even larger frames\n",
    "    large_grid = np.kron(grid, np.ones((scale_factor, scale_factor)))\n",
    "\n",
    "    # Assume goal_position and all grid positions are initially 0 (black)\n",
    "    # Set the goal position to 1 (white)\n",
    "    grid[goal_position] = 1\n",
    "\n",
    "    for step in range(100):  # Assume a maximum of 100 steps\n",
    "        # Update the grid with the current agent position (set to 1 for white)\n",
    "        grid[start_position] = 1\n",
    "        large_grid = np.kron(grid, np.ones((scale_factor, scale_factor)))  # Scale up\n",
    "        frame = (large_grid * 255).astype(np.uint8)  # Convert to an image\n",
    "        frame = np.stack((frame,) * 3, axis=-1)  # Convert to RGB\n",
    "\n",
    "        # Repeat each frame three times\n",
    "        for _ in range(3):\n",
    "            writer.append_data(frame)\n",
    "\n",
    "        # Set the agent's previous position back to 0 (black)\n",
    "        grid[start_position] = 0\n",
    "\n",
    "        # Move the agent\n",
    "        action = agent.choose_action(start_position)\n",
    "        next_position = agent.get_next_state(start_position, action)\n",
    "\n",
    "        # If the agent reaches the goal, update the grid and append the final frames\n",
    "        if next_position == goal_position:\n",
    "            grid[next_position] = 1  # Set the agent position to white\n",
    "            large_grid = np.kron(grid, np.ones((scale_factor, scale_factor)))\n",
    "            final_frame = (large_grid * 255).astype(np.uint8)\n",
    "            final_frame = np.stack((final_frame,) * 3, axis=-1)\n",
    "            for _ in range(3):\n",
    "                writer.append_data(final_frame)\n",
    "            break  # Break after showing the final move\n",
    "\n",
    "        # Update the start position for the next step\n",
    "        start_position = next_position\n",
    "\n",
    "    writer.close()  # Close the writer to finalize the video\n",
    "\n",
    "    return \"videos/\" + filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/untrained.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untrained agent\n",
    "Video(make_video(SARSAAgent(), bitmap, (np.random.randint(8), np.random.randint(8)), goal_position, filename=\"untrained.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"videos/trained.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trained agent\n",
    "Video(make_video(sarsa_agent, bitmap, (np.random.randint(8), np.random.randint(8)), goal_position, filename=\"trained.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-organising-systems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
